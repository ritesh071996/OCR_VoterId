{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import math\n",
    "import tabula\n",
    "import camelot\n",
    "import pdfminer\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "try:\n",
    "    from cStringIO import StringIO\n",
    "except ImportError:\n",
    "    from io import StringIO \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "8\n",
      "\n",
      "length of first_check: 9\n",
      "Column length greater than 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\rites\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\pandas\\core\\frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "c:\\users\\rites\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:249: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st attempt\n",
      "list3\n",
      "parsed_completed\n",
      "Completed.\n"
     ]
    }
   ],
   "source": [
    "def abc(a):\n",
    "    if type(a) ==str:\n",
    "        if len(a.split(' '))==2:\n",
    "            z=a.split(' ')[1]\n",
    "        else:\n",
    "            z=a.split(' ')[0]\n",
    "    else :\n",
    "        z=a\n",
    "    return z\n",
    "\n",
    "def isnan(value):\n",
    "    try:\n",
    "        return math.isnan(float(value))\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def backfill(df, narr):\n",
    "    print(\"backfill\")\n",
    "    df = df[pd.notnull(df[narr])]\n",
    "    df.iloc[:,-1]=df.iloc[:,-1].fillna(df.iloc[:,-2])\n",
    "    \n",
    "    try:\n",
    "        bal=[c for c in df.columns if \"BALANCE\" in str(c).upper()][0]\n",
    "        df[bal]=df[bal].apply(lambda x: abc(x))\n",
    "    except:\n",
    "        print(\"\\nBalance Column Missing\")\n",
    "        \n",
    "    df[\"flag\"]=df.iloc[:,-1].shift(1)\n",
    "    df=df[~df.index.isin(df[df.iloc[:,-1]==df.iloc[:,-2]].index)]\n",
    "\n",
    "    df=df.T.drop_duplicates().T\n",
    "    df[bal]=df[bal].apply(lambda x: str(x).replace(\",\",\"\").replace(\"(Cr)\",\"\").replace(\"(Dr)\",\"\")).astype(float)\n",
    "    df[\"flag\"]=df.iloc[:,0].astype(str)+df[bal].astype(str)\n",
    "    df[\"flag2\"]=np.arange(len(df))\n",
    "\n",
    "    df.loc[df[[\"flag\"]].duplicated(keep=False), 'flag'] = df[\"flag\"]+df[\"flag2\"].astype(str)\n",
    "    df['flag']=df['flag'].apply(lambda row : np.nan if 'nannan' in row else row).fillna(method='bfill')\n",
    "\n",
    "    df[narr]=df.groupby('flag')[narr].transform(lambda x:''.join(x))\n",
    "    df=df.drop_duplicates(['flag'],keep='last').iloc[0:,:-2].reset_index(drop=True)\n",
    "    df.to_csv(\"parsed_completed.csv\",index=0)\n",
    "    print(\"parsed_completed\")\n",
    "    return df\n",
    "\n",
    "def proceed(df):\n",
    "    try:\n",
    "        idx=[ c for c in df[df.apply(lambda row: row.astype(str).str.lower().str.contains('balance').any(), axis=1) ==True].index if c in df[df.apply(lambda row: row.astype(str).str.lower().str.contains('date').any(), axis=1) ==True].index ][0]\n",
    "        df.columns=df.iloc[idx] ; df=df.iloc[idx+1:,:] ; df.reset_index(drop=True,inplace=True)\n",
    "        print(\"1st attempt\")\n",
    "    except:\n",
    "        try:\n",
    "            idx=[ c for c in df[df.apply(lambda row: row.astype(str).str.lower().str.contains('balance').any(), axis=1) ==True].index if c in df[df.apply(lambda row: row.astype(str).str.lower().str.contains('particular').any(), axis=1) ==True].index ][0]\n",
    "            df.columns=df.iloc[idx] ; df=df.iloc[idx+1:,:] ; df.reset_index(drop=True,inplace=True)           \n",
    "        except:\n",
    "            print(\"\\nAxis-Column headers missing\"); pass\n",
    "\n",
    "    try:\n",
    "        df = df.drop([\"Init.\"], axis=1)\n",
    "    except:\n",
    "        try:\n",
    "            df = df.drop([\"Branch Name\"], axis=1)\n",
    "        except:pass\n",
    "\n",
    "    df=df[~df.index.isin(df[df.apply(lambda row: row.astype(str).str.lower().str.contains('transaction total|closing balance|particulars|transaction').any(), axis=1) ==True].index)]\n",
    "    #df.drop(df.nunique(dropna=False)[(df.nunique(dropna=False) == 1)].index, axis=1,inplace=True)\n",
    "\n",
    "    try:\n",
    "        narr=[n for n in df.columns if \"PARTICULARS\" in str(n).upper()][0]\n",
    "    except:\n",
    "        try:\n",
    "            narr=[n for n in df.columns if \"NARRATION\" in str(n).upper()][0]\n",
    "        except:\n",
    "            try:\n",
    "                narr=[n for n in df.columns if \"DESCRIPTION\" in str(n).upper()][0] \n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    list1 = ['Tran Date','Chq No','Particulars','Debit','Credit','Balance']\n",
    "    list2 = ['Tran Date','Value Date','Transaction Particulars','Chq No','Amount(INR)','DR/CR','Balance(INR)']\n",
    "    list3 = ['Tran Date','Value Date','Transaction Particulars','Chq No.','Amount','DR|CR','Balance']\n",
    "\n",
    "    if list(df.columns.values) == list1 :\n",
    "        print(\"list1\")\n",
    "        df = backfill(df,narr)\n",
    "        \n",
    "    elif list(df.columns.values) == list2 :\n",
    "        print(\"list2\")\n",
    "        df = backfill(df,narr)\n",
    "\n",
    "    elif list(df.columns.values) == list3:\n",
    "        print(\"list3\")   \n",
    "        \n",
    "        try:\n",
    "            bal=[c for c in df.columns if \"BALANCE\" in str(c).upper()][0]\n",
    "            df[bal]=df[bal].apply(lambda x: abc(x))\n",
    "        except:\n",
    "            print(\"\\nBalance Column Missing\")\n",
    "\n",
    "        try:    \n",
    "            df.replace(r'^\\s*$', np.nan, regex=True, inplace = True)\n",
    "            #type(df[\"Transaction Particulars\"][15])\n",
    "        except:pass\n",
    "\n",
    "        try:\n",
    "            df.dropna(axis=0, how='all',inplace=True)\n",
    "        except:pass\n",
    "\n",
    "        try:\n",
    "            df.reset_index(drop=True,inplace=True)\n",
    "        except:pass\n",
    "\n",
    "        try:\n",
    "            for j,i in enumerate(df[\"Transaction Particulars\"]):\n",
    "                if isnan(i) == True:\n",
    "                    df[narr][j] = df[narr][j-1]+df[narr][j+1]\n",
    "                else:\n",
    "                    pass\n",
    "        except:pass\n",
    "\n",
    "        try:\n",
    "            df.dropna(subset=['Tran Date'], inplace = True)\n",
    "        except:\n",
    "            try:\n",
    "                df.dropna(subset=['Value Date'], inplace = True)\n",
    "            except:pass\n",
    "\n",
    "        df.to_csv(\"parsed_completed.csv\",index=0)\n",
    "        print(\"parsed_completed\")\n",
    "        \n",
    "    else:\n",
    "        print(\"In Proceed, Another pattern found\")\n",
    "    return df\n",
    "        \n",
    "\n",
    "def came(f):\n",
    "    tables = camelot.read_pdf(f, flavor='stream', pages='1,2', edge_tol=500)\n",
    "    if len(tables) != 0:\n",
    "        dt=pd.DataFrame(); tmp=pd.DataFrame()\n",
    "        first_check = tables[0].df; second_check = tables[1].df;\n",
    "        print(first_check.shape[1])\n",
    "        print(second_check.shape[1])\n",
    "        if (first_check.shape[1] > 5):\n",
    "            try:\n",
    "                idx=[ c for c in first_check[first_check.apply(lambda row: row.astype(str).str.lower().str.contains('balance').any(), axis=1) ==True].index if c in first_check[first_check.apply(lambda row: row.astype(str).str.lower().str.contains('date').any(), axis=1) ==True].index ][0]\n",
    "                first_check.columns=first_check.iloc[idx]\n",
    "            except:\n",
    "                try:\n",
    "                    idx=[ c for c in first_check[first_check.apply(lambda row: row.astype(str).str.lower().str.contains('balance').any(), axis=1) ==True].index if c in dt[dt.apply(lambda row: row.astype(str).str.lower().str.contains('particular').any(), axis=1) ==True].index ][0]\n",
    "                    first_check.columns=first_check.iloc[idx]\n",
    "                except:\n",
    "                    print(\"\\nAxis-Column headers missing\")\n",
    "            tables2 = camelot.read_pdf(f, flavor='stream', pages='all', edge_tol=500)\n",
    "            print(\"\\nlength of first_check:\",len(first_check.columns))\n",
    "            if len(first_check.columns) == 7:\n",
    "                print(\"Column length is 7\")\n",
    "                for i in range(len(tables2)):\n",
    "                    tmp=tables2[i].df\n",
    "                    if (tmp.shape[1] < 5):\n",
    "                        print(\"\\nDiiferent structure on page:\",i); pass\n",
    "                    elif (tmp.shape[1] == 7):\n",
    "                        tmp=pd.DataFrame(tmp).replace(r'^\\s*$', np.nan, regex=True)\n",
    "                        dt = pd.concat([dt,tmp]).reset_index(drop=True)\n",
    "                    elif (tmp.shape[1] == 6):\n",
    "                        tmp=pd.DataFrame(tmp).replace(r'^\\s*$', np.nan, regex=True)\n",
    "                        tmp[6] = np.nan; tmp = tmp[[0,6,1,2,3,4,5]]; tmp.columns = range(tmp.shape[1]);\n",
    "                        dt = pd.concat([dt,tmp]).reset_index(drop=True)\n",
    "                    else:\n",
    "                        print(\"\\nAnother Structure on page:\",i); pass\n",
    "\n",
    "            elif len(first_check.columns) == 8:\n",
    "                print(\"Column length is 8\")\n",
    "                for i in range(len(tables2)):\n",
    "                    tmp=tables2[i].df   \n",
    "                    if (tmp.shape[1] < 5):\n",
    "                        print(\"\\nDiiferent structure on page:\",i); pass\n",
    "                    elif (tmp.shape[1] == 8):\n",
    "                        tmp=pd.DataFrame(tmp).replace(r'^\\s*$', np.nan, regex=True)\n",
    "                        dt = pd.concat([dt,tmp]).reset_index(drop=True)\n",
    "                    elif (tmp.shape[1] == 7):\n",
    "                        tmp=pd.DataFrame(tmp).replace(r'^\\s*$', np.nan, regex=True)\n",
    "                        tmp[7] = np.nan; tmp = tmp[[0,1,2,7,3,4,5,6]]; tmp.columns = range(tmp.shape[1]);\n",
    "                        dt = pd.concat([dt,tmp]).reset_index(drop=True)\n",
    "                    else:\n",
    "                        print(\"\\nAnother Structure on page:\",i); pass\n",
    "            elif len(first_check.columns) > 8:\n",
    "                print(\"Column length greater than 8\")\n",
    "                for i in range(len(tables2)):\n",
    "                    tmp=tables2[i].df \n",
    "                    if (tmp.shape[1] > 8):\n",
    "                        try:\n",
    "                            idx=[ c for c in tmp[tmp.apply(lambda row: row.astype(str).str.lower().str.contains('balance').any(), axis=1) ==True].index if c in tmp[tmp.apply(lambda row: row.astype(str).str.lower().str.contains('date').any(), axis=1) ==True].index ][0]\n",
    "                            tmp.columns=tmp.iloc[idx] ; tmp=tmp.iloc[idx:,:] ; tmp.reset_index(drop=True,inplace=True)\n",
    "                        except:\n",
    "                            try:\n",
    "                                idx=[ c for c in tmp[tmp.apply(lambda row: row.astype(str).str.lower().str.contains('balance').any(), axis=1) ==True].index if c in tmp[tmp.apply(lambda row: row.astype(str).str.lower().str.contains('particular').any(), axis=1) ==True].index ][0]\n",
    "                                tmp.columns=tmp.iloc[idx] ; tmp=tmp.iloc[idx:,:] ; tmp.reset_index(drop=True,inplace=True)           \n",
    "                            except:\n",
    "                                print(\"\\nAxis-Column headers missing\"); pass\n",
    "                        tmp.drop(\"\",axis = 1,inplace = True)\n",
    "                        tmp.columns = [0,1,2,3,4,5,6,7]\n",
    "                        tmp=pd.DataFrame(tmp).replace(r'^\\s*$', np.nan, regex=True)\n",
    "                        # print(\"\\n\",tmp)\n",
    "                        dt=pd.concat([dt,tmp]).reset_index(drop=True)\n",
    "                    elif (tmp.shape[1] == 8):\n",
    "                        tmp=pd.DataFrame(tmp).replace(r'^\\s*$', np.nan, regex=True)\n",
    "                        # print(\"\\n\",tmp)\n",
    "                        dt = pd.concat([dt,tmp]).reset_index(drop=True)\n",
    "                    elif (tmp.shape[1] == 7):\n",
    "                        tmp=pd.DataFrame(tmp).replace(r'^\\s*$', np.nan, regex=True)\n",
    "                        tmp[7] = np.nan; tmp = tmp[[0,1,2,7,3,4,5,6]]; tmp.columns = range(tmp.shape[1]);\n",
    "                        # print(\"\\n\",tmp)\n",
    "                        dt = pd.concat([dt,tmp]).reset_index(drop=True)\n",
    "                    elif (tmp.shape[1] == 6):\n",
    "                        try:\n",
    "                            idx=[ c for c in tmp[tmp.apply(lambda row: row.astype(str).str.lower().str.contains('balance').any(), axis=1) ==True].index if c in tmp[tmp.apply(lambda row: row.astype(str).str.lower().str.contains('date').any(), axis=1) ==True].index ][0]\n",
    "                        except:\n",
    "                            try:\n",
    "                                idx=[ c for c in tmp[tmp.apply(lambda row: row.astype(str).str.lower().str.contains('balance').any(), axis=1) ==True].index if c in tmp[tmp.apply(lambda row: row.astype(str).str.lower().str.contains('particular').any(), axis=1) ==True].index ][0]\n",
    "                            except:\n",
    "                                print(\"\\nAxis-Column headers missing\")\n",
    "                        tmp.columns=tmp.iloc[idx] ; tmp=tmp.iloc[idx+1:,:] ; tmp.reset_index(drop=True,inplace=True) \n",
    "                        tmp=tmp[~tmp.index.isin(tmp[tmp.apply(lambda row: row.astype(str).str.lower().str.contains('page:|account status|total|reason for return|inward clg|opening balance|statement of a/c').any(), axis=1) ==True].index)]\n",
    "                        if tmp.columns[0] == 'Tran Date\\nValue Date\\nTransaction Particulars':\n",
    "                            tmp.columns = [\"A\",\"B\",\"C\",\"D\",\"E\",\"F\"]\n",
    "                            tmp.reset_index(drop = True, inplace=True)\n",
    "                            tmp1 = pd.DataFrame(tmp.A.str.split('\\n',2).tolist(),columns=[\"Z1\", \"Z2\", \"Z3\"])\n",
    "                            result = pd.concat([tmp1, tmp], axis=1, sort=False)\n",
    "                            result.drop('A' ,axis=1, inplace=True)\n",
    "                            result[\"Y\"] = result[\"Z1\"]\n",
    "                            for i,j in enumerate(result[\"Y\"]):\n",
    "                                if re.search(r'(\\d+-\\d+-\\d+)',j):\n",
    "                                    result.at[i, 'Y'] = \"\"\n",
    "                                    pass\n",
    "                                elif re.search(r'^\\s*$',j):\n",
    "                                    result.at[i, 'Y'] = \"\"\n",
    "                                    pass\n",
    "                                else:\n",
    "                                    pass\n",
    "                                    \n",
    "                            for i,j in enumerate(result[\"Z1\"]):\n",
    "                                if re.search(r'(\\d+-\\d+-\\d+)',j):\n",
    "                                    pass\n",
    "                                elif re.search(r'^\\s*$',j):\n",
    "                                    result.at[i, 'Z1'] = \"\"\n",
    "                                    pass\n",
    "                                else:\n",
    "                                    result.at[i, 'Z1'] = \"\"\n",
    "                                    pass \n",
    "                            result.fillna(value=pd.np.nan, inplace=True)\n",
    "                            result['X'] = result['Z3'].fillna('') + result['Y'].fillna('')\n",
    "                            result.drop(['Z3','Y'] ,axis=1, inplace=True)\n",
    "                            result = result[['Z1', 'Z2', 'X', 'B', 'C','D','E','F']]\n",
    "                            result.columns = [0,1,2,3,4,5,6,7]\n",
    "                            result=pd.DataFrame(result).replace(r'^\\s*$', np.nan, regex=True)\n",
    "                            # print(\"\\n\",result)\n",
    "                            dt=pd.concat([dt,result]).reset_index(drop=True)\n",
    "                        else:\n",
    "                            print(\"\\nIn without box pdf another Structure on page:\",i); pass\n",
    "\n",
    "        elif(second_check.shape[1] > 5):\n",
    "            try:\n",
    "                idx=[ c for c in second_check[second_check.apply(lambda row: row.astype(str).str.lower().str.contains('balance').any(), axis=1) ==True].index if c in second_check[second_check.apply(lambda row: row.astype(str).str.lower().str.contains('date').any(), axis=1) ==True].index ][0]\n",
    "                second_check.columns=second_check.iloc[idx]\n",
    "            except:\n",
    "                try:\n",
    "                    idx=[ c for c in second_check[second_check.apply(lambda row: row.astype(str).str.lower().str.contains('balance').any(), axis=1) ==True].index if c in dt[dt.apply(lambda row: row.astype(str).str.lower().str.contains('particular').any(), axis=1) ==True].index ][0]\n",
    "                    second_check.columns=second_check.iloc[idx]\n",
    "                except:\n",
    "                    print(\"\\nAxis-Column headers missing\")\n",
    "            tables2 = camelot.read_pdf(f, flavor='stream', pages='all', edge_til=500)\n",
    "            if len(second_check.columns) == 7:\n",
    "                print(\"Column length is 7\")\n",
    "                for i in range(len(tables2)):\n",
    "                    tmp=tables2[i].df\n",
    "                    if (tmp.shape[1] < 5):\n",
    "                        print(\"\\nDiiferent structure on page:\",i); pass\n",
    "                    elif (tmp.shape[1] == 7):\n",
    "                        tmp=pd.DataFrame(tmp).replace(r'^\\s*$', np.nan, regex=True)\n",
    "                        dt = pd.concat([dt,tmp]).reset_index(drop=True)\n",
    "                    elif (tmp.shape[1] == 6):\n",
    "                        tmp=pd.DataFrame(tmp).replace(r'^\\s*$', np.nan, regex=True)\n",
    "                        tmp[6] = np.nan; tmp = tmp[[0,6,1,2,3,4,5]]; tmp.columns = range(tmp.shape[1]);\n",
    "                        dt = pd.concat([dt,tmp]).reset_index(drop=True)\n",
    "                    else:\n",
    "                        print(\"\\nAnother Structure on page:\",i); pass\n",
    "\n",
    "            elif len(second_check.columns) == 8:\n",
    "                print(\"Column length is 8\")\n",
    "                for i in range(len(tables2)):\n",
    "                    #print(\"\\n\",i,\":\",tmp.shape[1])\n",
    "                    tmp=tables2[i].df\n",
    "                    if (tmp.shape[1] < 5):\n",
    "                        print(\"\\nDiiferent structure on page:\",i); pass\n",
    "                    elif (tmp.shape[1] == 8):\n",
    "                        tmp=pd.DataFrame(tmp).replace(r'^\\s*$', np.nan, regex=True)\n",
    "                        dt = pd.concat([dt,tmp]).reset_index(drop=True)\n",
    "                    elif (tmp.shape[1] == 7):\n",
    "                        tmp=pd.DataFrame(tmp).replace(r'^\\s*$', np.nan, regex=True)\n",
    "                        tmp[7] = np.nan; tmp = tmp[[0,1,2,7,3,4,5,6]]; tmp.columns = range(tmp.shape[1]);\n",
    "                        dt = pd.concat([dt,tmp]).reset_index(drop=True)\n",
    "                    else:\n",
    "                        print(\"\\nAnother Structure on page:\",i); pass\n",
    "\n",
    "    else:\n",
    "        print(\"\\nLength of table is 0\"); pass   \n",
    "    return dt\n",
    "\n",
    "try:\n",
    "    f = r'C:\\Users\\rites\\Desktop\\mudracircle\\bks_raw\\Parsing_testing\\Axis_new\\axis_files\\axis03.pdf'\n",
    "    try:\n",
    "        df = came(f); df = proceed(df);\n",
    "        print(\"Completed.\")\n",
    "    except Exception as e:\n",
    "        print(\"Error : \",e)\n",
    "        print(\"Not parsed\")\n",
    "        pass\n",
    "except:\n",
    "    print(\"\\n Can't parse\") \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: No tables found in table area 1 [stream.py:361]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column length is 7\n",
      "\n",
      "Diiferent structure on page: 0\n",
      "\n",
      "Diiferent structure on page: 4\n",
      "\n",
      "Diiferent structure on page: 5\n",
      "1st attempt\n",
      "list1\n",
      "backfill\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\mudracircle\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\core\\indexing.py:576: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item_labels[indexer[info_axis]]] = value\n",
      "c:\\users\\mudracircle\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\mudracircle\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsed_completed\n",
      "Completed.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import math\n",
    "import tabula\n",
    "import camelot\n",
    "import pdfminer\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "try:\n",
    "    from cStringIO import StringIO\n",
    "except ImportError:\n",
    "    from io import StringIO \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def abc(a):\n",
    "    if type(a) ==str:\n",
    "        if len(a.split(' '))==2:\n",
    "            z=a.split(' ')[1]\n",
    "        else:\n",
    "            z=a.split(' ')[0]\n",
    "    else :\n",
    "        z=a\n",
    "    return z\n",
    "\n",
    "def isnan(value):\n",
    "    try:\n",
    "        return math.isnan(float(value))\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def backfill(df, narr):\n",
    "    print(\"backfill\")\n",
    "    df = df[pd.notnull(df[narr])]\n",
    "    df.iloc[:,-1]=df.iloc[:,-1].fillna(df.iloc[:,-2])\n",
    "    \n",
    "    try:\n",
    "        bal=[c for c in df.columns if \"BALANCE\" in str(c).upper()][0]\n",
    "        df[bal]=df[bal].apply(lambda x: abc(x))\n",
    "    except:\n",
    "        print(\"\\nBalance Column Missing\")\n",
    "        \n",
    "    df[\"flag\"]=df.iloc[:,-1].shift(1)\n",
    "    df=df[~df.index.isin(df[df.iloc[:,-1]==df.iloc[:,-2]].index)]\n",
    "\n",
    "    df=df.T.drop_duplicates().T\n",
    "    df[bal]=df[bal].apply(lambda x: str(x).replace(\",\",\"\").replace(\"(Cr)\",\"\").replace(\"(Dr)\",\"\")).astype(float)\n",
    "    df[\"flag\"]=df.iloc[:,0].astype(str)+df[bal].astype(str)\n",
    "    df[\"flag2\"]=np.arange(len(df))\n",
    "\n",
    "    df.loc[df[[\"flag\"]].duplicated(keep=False), 'flag'] = df[\"flag\"]+df[\"flag2\"].astype(str)\n",
    "    df['flag']=df['flag'].apply(lambda row : np.nan if 'nannan' in row else row).fillna(method='bfill')\n",
    "\n",
    "    df[narr]=df.groupby('flag')[narr].transform(lambda x:''.join(x))\n",
    "    df=df.drop_duplicates(['flag'],keep='last').iloc[0:,:-2].reset_index(drop=True)\n",
    "    df.to_csv(\"parsed_completed.csv\",index=0)\n",
    "    print(\"parsed_completed\")\n",
    "    return df\n",
    "\n",
    "def proceed(df):\n",
    "    try:\n",
    "        idx=[ c for c in df[df.apply(lambda row: row.astype(str).str.lower().str.contains('balance').any(), axis=1) ==True].index if c in df[df.apply(lambda row: row.astype(str).str.lower().str.contains('date').any(), axis=1) ==True].index ][0]\n",
    "        df.columns=df.iloc[idx] ; df=df.iloc[idx+1:,:] ; df.reset_index(drop=True,inplace=True)\n",
    "        print(\"1st attempt\")\n",
    "    except:\n",
    "        try:\n",
    "            idx=[ c for c in df[df.apply(lambda row: row.astype(str).str.lower().str.contains('balance').any(), axis=1) ==True].index if c in df[df.apply(lambda row: row.astype(str).str.lower().str.contains('particular').any(), axis=1) ==True].index ][0]\n",
    "            df.columns=df.iloc[idx] ; df=df.iloc[idx+1:,:] ; df.reset_index(drop=True,inplace=True)           \n",
    "        except:\n",
    "            print(\"\\nAxis-Column headers missing\"); pass\n",
    "\n",
    "    try:\n",
    "        df = df.drop([\"Init.\"], axis=1)\n",
    "    except:\n",
    "        try:\n",
    "            df = df.drop([\"Branch Name\"], axis=1)\n",
    "        except:pass\n",
    "\n",
    "    df=df[~df.index.isin(df[df.apply(lambda row: row.astype(str).str.lower().str.contains('opening balance|transaction total|closing balance|particulars|transaction').any(), axis=1) ==True].index)]\n",
    "    #df.drop(df.nunique(dropna=False)[(df.nunique(dropna=False) == 1)].index, axis=1,inplace=True)\n",
    "\n",
    "    try:\n",
    "        narr=[n for n in df.columns if \"PARTICULARS\" in str(n).upper()][0]\n",
    "    except:\n",
    "        try:\n",
    "            narr=[n for n in df.columns if \"NARRATION\" in str(n).upper()][0]\n",
    "        except:\n",
    "            try:\n",
    "                narr=[n for n in df.columns if \"DESCRIPTION\" in str(n).upper()][0] \n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    list1 = ['Tran Date','Chq No','Particulars','Debit','Credit','Balance']\n",
    "    list2 = ['Tran Date','Value Date','Transaction Particulars','Chq No','Amount(INR)','DR/CR','Balance(INR)']\n",
    "    list3 = ['Tran Date','Value Date','Transaction Particulars','Chq No.','Amount','DR|CR','Balance']\n",
    "\n",
    "    if list(df.columns.values) == list1 :\n",
    "        print(\"list1\")\n",
    "        df = backfill(df,narr)\n",
    "        \n",
    "    elif list(df.columns.values) == list2 :\n",
    "        print(\"list2\")\n",
    "        df = backfill(df,narr)\n",
    "\n",
    "    elif list(df.columns.values) == list3:\n",
    "        print(\"list3\")   \n",
    "        \n",
    "        try:\n",
    "            bal=[c for c in df.columns if \"BALANCE\" in str(c).upper()][0]\n",
    "            df[bal]=df[bal].apply(lambda x: abc(x))\n",
    "        except:\n",
    "            print(\"\\nBalance Column Missing\")\n",
    "\n",
    "        try:    \n",
    "            df.replace(r'^\\s*$', np.nan, regex=True, inplace = True)\n",
    "            #type(df[\"Transaction Particulars\"][15])\n",
    "        except:pass\n",
    "\n",
    "        try:\n",
    "            df.dropna(axis=0, how='all',inplace=True)\n",
    "        except:pass\n",
    "\n",
    "        try:\n",
    "            df.reset_index(drop=True,inplace=True)\n",
    "        except:pass\n",
    "\n",
    "        try:\n",
    "            for j,i in enumerate(df[\"Transaction Particulars\"]):\n",
    "                if isnan(i) == True:\n",
    "                    df[narr][j] = df[narr][j-1]+df[narr][j+1]\n",
    "                else:\n",
    "                    pass\n",
    "        except:pass\n",
    "\n",
    "        try:\n",
    "            df.dropna(subset=['Tran Date'], inplace = True)\n",
    "        except:\n",
    "            try:\n",
    "                df.dropna(subset=['Value Date'], inplace = True)\n",
    "            except:pass\n",
    "\n",
    "        df.to_csv(\"parsed_completed.csv\",index=0)\n",
    "        print(\"parsed_completed\")\n",
    "        \n",
    "    else:\n",
    "        print(\"In Proceed, Another pattern found\")\n",
    "    return df\n",
    "\n",
    "def came(f):\n",
    "    tables = camelot.read_pdf(f, flavor='stream', pages='1,2', edge_tol=500)\n",
    "    if len(tables) != 0:\n",
    "        dt=pd.DataFrame(); tmp=pd.DataFrame()\n",
    "        first_check = tables[0].df; second_check = tables[1].df;\n",
    "        # print(first_check.shape[1])\n",
    "        # print(second_check.shape[1])\n",
    "        if (first_check.shape[1] > 5):\n",
    "            try:\n",
    "                idx=[ c for c in first_check[first_check.apply(lambda row: row.astype(str).str.lower().str.contains('balance').any(), axis=1) ==True].index if c in first_check[first_check.apply(lambda row: row.astype(str).str.lower().str.contains('date').any(), axis=1) ==True].index ][0]\n",
    "                first_check.columns=first_check.iloc[idx]\n",
    "            except:\n",
    "                try:\n",
    "                    idx=[ c for c in first_check[first_check.apply(lambda row: row.astype(str).str.lower().str.contains('balance').any(), axis=1) ==True].index if c in dt[dt.apply(lambda row: row.astype(str).str.lower().str.contains('particular').any(), axis=1) ==True].index ][0]\n",
    "                    first_check.columns=first_check.iloc[idx]\n",
    "                except:\n",
    "                    print(\"\\nAxis-Column headers missing\")\n",
    "            tables2 = camelot.read_pdf(f, flavor='stream', pages='all', edge_tol=500)\n",
    "            print(\"\\nlength of first_check:\",len(first_check.columns))\n",
    "            if len(first_check.columns) == 7:\n",
    "                print(\"Column length is 7\")\n",
    "                for i in range(len(tables2)):\n",
    "                    tmp=tables2[i].df\n",
    "                    if (tmp.shape[1] < 5):\n",
    "                        print(\"\\nDiiferent structure on page:\",i); pass\n",
    "                    elif (tmp.shape[1] == 7):\n",
    "                        tmp=pd.DataFrame(tmp).replace(r'^\\s*$', np.nan, regex=True)\n",
    "                        dt = pd.concat([dt,tmp]).reset_index(drop=True)\n",
    "                    elif (tmp.shape[1] == 6):\n",
    "                        tmp=pd.DataFrame(tmp).replace(r'^\\s*$', np.nan, regex=True)\n",
    "                        tmp[6] = np.nan; tmp = tmp[[0,6,1,2,3,4,5]]; tmp.columns = range(tmp.shape[1]);\n",
    "                        dt = pd.concat([dt,tmp]).reset_index(drop=True)\n",
    "                    else:\n",
    "                        print(\"\\nAnother Structure on page:\",i); pass\n",
    "\n",
    "            elif len(first_check.columns) == 8:\n",
    "                print(\"Column length is 8\")\n",
    "                for i in range(len(tables2)):\n",
    "                    tmp=tables2[i].df   \n",
    "                    if (tmp.shape[1] < 5):\n",
    "                        print(\"\\nDiiferent structure on page:\",i); pass\n",
    "                    elif (tmp.shape[1] == 8):\n",
    "                        tmp=pd.DataFrame(tmp).replace(r'^\\s*$', np.nan, regex=True)\n",
    "                        dt = pd.concat([dt,tmp]).reset_index(drop=True)\n",
    "                    elif (tmp.shape[1] == 7):\n",
    "                        tmp=pd.DataFrame(tmp).replace(r'^\\s*$', np.nan, regex=True)\n",
    "                        tmp[7] = np.nan; tmp = tmp[[0,1,2,7,3,4,5,6]]; tmp.columns = range(tmp.shape[1]);\n",
    "                        dt = pd.concat([dt,tmp]).reset_index(drop=True)\n",
    "                    else:\n",
    "                        print(\"\\nAnother Structure on page:\",i); pass\n",
    "            elif len(first_check.columns) > 8:\n",
    "                print(\"Column length greater than 8\")\n",
    "                for i in range(len(tables2)):\n",
    "                    tmp=tables2[i].df \n",
    "                    if (tmp.shape[1] > 8):\n",
    "                        try:\n",
    "                            idx=[ c for c in tmp[tmp.apply(lambda row: row.astype(str).str.lower().str.contains('balance').any(), axis=1) ==True].index if c in tmp[tmp.apply(lambda row: row.astype(str).str.lower().str.contains('date').any(), axis=1) ==True].index ][0]\n",
    "                            tmp.columns=tmp.iloc[idx] ; tmp=tmp.iloc[idx:,:] ; tmp.reset_index(drop=True,inplace=True)\n",
    "                        except:\n",
    "                            try:\n",
    "                                idx=[ c for c in tmp[tmp.apply(lambda row: row.astype(str).str.lower().str.contains('balance').any(), axis=1) ==True].index if c in tmp[tmp.apply(lambda row: row.astype(str).str.lower().str.contains('particular').any(), axis=1) ==True].index ][0]\n",
    "                                tmp.columns=tmp.iloc[idx] ; tmp=tmp.iloc[idx:,:] ; tmp.reset_index(drop=True,inplace=True)           \n",
    "                            except:\n",
    "                                print(\"\\nAxis-Column headers missing\"); pass\n",
    "                        tmp.drop(\"\",axis = 1,inplace = True)\n",
    "                        tmp.columns = [0,1,2,3,4,5,6,7]\n",
    "                        tmp=pd.DataFrame(tmp).replace(r'^\\s*$', np.nan, regex=True)\n",
    "                        # print(\"\\n\",tmp)\n",
    "                        dt=pd.concat([dt,tmp]).reset_index(drop=True)\n",
    "                    elif (tmp.shape[1] == 8):\n",
    "                        tmp=pd.DataFrame(tmp).replace(r'^\\s*$', np.nan, regex=True)\n",
    "                        # print(\"\\n\",tmp)\n",
    "                        dt = pd.concat([dt,tmp]).reset_index(drop=True)\n",
    "                    elif (tmp.shape[1] == 7):\n",
    "                        tmp=pd.DataFrame(tmp).replace(r'^\\s*$', np.nan, regex=True)\n",
    "                        tmp[7] = np.nan; tmp = tmp[[0,1,2,7,3,4,5,6]]; tmp.columns = range(tmp.shape[1]);\n",
    "                        # print(\"\\n\",tmp)\n",
    "                        dt = pd.concat([dt,tmp]).reset_index(drop=True)\n",
    "                    elif (tmp.shape[1] == 6):\n",
    "                        try:\n",
    "                            idx=[ c for c in tmp[tmp.apply(lambda row: row.astype(str).str.lower().str.contains('balance').any(), axis=1) ==True].index if c in tmp[tmp.apply(lambda row: row.astype(str).str.lower().str.contains('date').any(), axis=1) ==True].index ][0]\n",
    "                        except:\n",
    "                            try:\n",
    "                                idx=[ c for c in tmp[tmp.apply(lambda row: row.astype(str).str.lower().str.contains('balance').any(), axis=1) ==True].index if c in tmp[tmp.apply(lambda row: row.astype(str).str.lower().str.contains('particular').any(), axis=1) ==True].index ][0]\n",
    "                            except:\n",
    "                                print(\"\\nAxis-Column headers missing\")\n",
    "                        tmp.columns=tmp.iloc[idx] ; tmp=tmp.iloc[idx+1:,:] ; tmp.reset_index(drop=True,inplace=True) \n",
    "                        tmp=tmp[~tmp.index.isin(tmp[tmp.apply(lambda row: row.astype(str).str.lower().str.contains('page:|account status|total|reason for return|inward clg|opening balance|statement of a/c').any(), axis=1) ==True].index)]\n",
    "                        if tmp.columns[0] == 'Tran Date\\nValue Date\\nTransaction Particulars':\n",
    "                            tmp.columns = [\"A\",\"B\",\"C\",\"D\",\"E\",\"F\"]\n",
    "                            tmp.reset_index(drop = True, inplace=True)\n",
    "                            tmp1 = pd.DataFrame(tmp.A.str.split('\\n',2).tolist(),columns=[\"Z1\", \"Z2\", \"Z3\"])\n",
    "                            result = pd.concat([tmp1, tmp], axis=1, sort=False)\n",
    "                            result.drop('A' ,axis=1, inplace=True)\n",
    "                            result[\"Y\"] = result[\"Z1\"]\n",
    "                            for i,j in enumerate(result[\"Y\"]):\n",
    "                                if re.search(r'(\\d+-\\d+-\\d+)',j):\n",
    "                                    result.at[i, 'Y'] = \"\"\n",
    "                                    pass\n",
    "                                elif re.search(r'^\\s*$',j):\n",
    "                                    result.at[i, 'Y'] = \"\"\n",
    "                                    pass\n",
    "                                else:\n",
    "                                    pass\n",
    "                                    \n",
    "                            for i,j in enumerate(result[\"Z1\"]):\n",
    "                                if re.search(r'(\\d+-\\d+-\\d+)',j):\n",
    "                                    pass\n",
    "                                elif re.search(r'^\\s*$',j):\n",
    "                                    result.at[i, 'Z1'] = \"\"\n",
    "                                    pass\n",
    "                                else:\n",
    "                                    result.at[i, 'Z1'] = \"\"\n",
    "                                    pass \n",
    "                            result.fillna(value=pd.np.nan, inplace=True)\n",
    "                            result['X'] = result['Z3'].fillna('') + result['Y'].fillna('')\n",
    "                            result.drop(['Z3','Y'] ,axis=1, inplace=True)\n",
    "                            result = result[['Z1', 'Z2', 'X', 'B', 'C','D','E','F']]\n",
    "                            result.columns = [0,1,2,3,4,5,6,7]\n",
    "                            result=pd.DataFrame(result).replace(r'^\\s*$', np.nan, regex=True)\n",
    "                            # print(\"\\n\",result)\n",
    "                            dt=pd.concat([dt,result]).reset_index(drop=True)\n",
    "                        else:\n",
    "                            print(\"\\nIn without box pdf another Structure on page:\",i); pass\n",
    "\n",
    "        elif(second_check.shape[1] > 5):\n",
    "            try:\n",
    "                idx=[ c for c in second_check[second_check.apply(lambda row: row.astype(str).str.lower().str.contains('balance').any(), axis=1) ==True].index if c in second_check[second_check.apply(lambda row: row.astype(str).str.lower().str.contains('date').any(), axis=1) ==True].index ][0]\n",
    "                second_check.columns=second_check.iloc[idx]\n",
    "            except:\n",
    "                try:\n",
    "                    idx=[ c for c in second_check[second_check.apply(lambda row: row.astype(str).str.lower().str.contains('balance').any(), axis=1) ==True].index if c in dt[dt.apply(lambda row: row.astype(str).str.lower().str.contains('particular').any(), axis=1) ==True].index ][0]\n",
    "                    second_check.columns=second_check.iloc[idx]\n",
    "                except:\n",
    "                    print(\"\\nAxis-Column headers missing\")\n",
    "            tables2 = camelot.read_pdf(f, flavor='stream', pages='all', edge_til=500)\n",
    "            if len(second_check.columns) == 7:\n",
    "                print(\"Column length is 7\")\n",
    "                for i in range(len(tables2)):\n",
    "                    tmp=tables2[i].df\n",
    "                    if (tmp.shape[1] < 5):\n",
    "                        print(\"\\nDiiferent structure on page:\",i); pass\n",
    "                    elif (tmp.shape[1] == 7):\n",
    "                        tmp=pd.DataFrame(tmp).replace(r'^\\s*$', np.nan, regex=True)\n",
    "                        dt = pd.concat([dt,tmp]).reset_index(drop=True)\n",
    "                    elif (tmp.shape[1] == 6):\n",
    "                        tmp=pd.DataFrame(tmp).replace(r'^\\s*$', np.nan, regex=True)\n",
    "                        tmp[6] = np.nan; tmp = tmp[[0,6,1,2,3,4,5]]; tmp.columns = range(tmp.shape[1]);\n",
    "                        dt = pd.concat([dt,tmp]).reset_index(drop=True)\n",
    "                    else:\n",
    "                        print(\"\\nAnother Structure on page:\",i); pass\n",
    "\n",
    "            elif len(second_check.columns) == 8:\n",
    "                print(\"Column length is 8\")\n",
    "                for i in range(len(tables2)):\n",
    "                    #print(\"\\n\",i,\":\",tmp.shape[1])\n",
    "                    tmp=tables2[i].df\n",
    "                    if (tmp.shape[1] < 5):\n",
    "                        print(\"\\nDiiferent structure on page:\",i); pass\n",
    "                    elif (tmp.shape[1] == 8):\n",
    "                        tmp=pd.DataFrame(tmp).replace(r'^\\s*$', np.nan, regex=True)\n",
    "                        dt = pd.concat([dt,tmp]).reset_index(drop=True)\n",
    "                    elif (tmp.shape[1] == 7):\n",
    "                        tmp=pd.DataFrame(tmp).replace(r'^\\s*$', np.nan, regex=True)\n",
    "                        tmp[7] = np.nan; tmp = tmp[[0,1,2,7,3,4,5,6]]; tmp.columns = range(tmp.shape[1]);\n",
    "                        dt = pd.concat([dt,tmp]).reset_index(drop=True)\n",
    "                    else:\n",
    "                        print(\"\\nAnother Structure on page:\",i); pass\n",
    "\n",
    "    else:\n",
    "        print(\"\\nLength of table is 0\"); pass   \n",
    "    return dt\n",
    "\n",
    "def axis_filter(df):\n",
    "    try:\n",
    "        drcr=[c for c in df.columns if \"DR\" in str(c).upper() ][0]\n",
    "        amt = [c for c in df.columns if \"AMOUNT\" in str(c).upper()][0]\n",
    "        print(drcr,amt)\n",
    "        df[\"Credits\"] = \"\"\n",
    "        df[\"Debits\"] = \"\"\n",
    "    except:pass\n",
    "\n",
    "    try:\n",
    "        for i in df.index:\n",
    "            if df[drcr][i] == \"DR\":\n",
    "                df[\"Debits\"][i] = df[amt][i]\n",
    "            elif df[drcr][i] == \"CR\":\n",
    "                df[\"Credits\"][i] = df[amt][i]\n",
    "            else:\n",
    "                print(i)\n",
    "                print(\"Dr & CR Absent\")\n",
    "    except:pass\n",
    "\n",
    "    try:\n",
    "        dat=[c for c in df.columns if \"TRANSACTION DATE\" in str(c).upper() ][0]\n",
    "    except:\n",
    "        try:\n",
    "            dat=[c for c in df.columns if \"TXN DATE\" in str(c).upper() ][0]\n",
    "        except:\n",
    "            try:\n",
    "                dat=[c for c in df.columns if \"DATE\" in str(c).upper() ][0]\n",
    "            except:pass\n",
    "\n",
    "    try:\n",
    "        chq=[c for c in df.columns if \"CHQ\" in str(c).upper() ][0]\n",
    "    except:\n",
    "        try:\n",
    "            chq=[c for c in df.columns if \"CHEQUE\" in str(c).upper() ][0]\n",
    "        except:pass\n",
    "\n",
    "    try:\n",
    "        narr=[c for c in df.columns if \"REMARKS\" in str(c).upper() ][0]\n",
    "    except:\n",
    "        try:\n",
    "            narr=[c for c in df.columns if \"PARTICULARS\" in str(c).upper() ][0]\n",
    "        except:\n",
    "            try:\n",
    "                narr=[c for c in df.columns if \"DESCRIPTION\" in str(c).upper() ][0]\n",
    "            except:\n",
    "                try:\n",
    "                    narr=[c for c in df.columns if \"DETAILS\" in str(c).upper() ][0]\n",
    "                except:pass\n",
    "\n",
    "    try:\n",
    "        bal=[c for c in df.columns if \"BALANCE\" in str(c).upper() ][0]\n",
    "        df[\"bal\"]=df[bal].apply( lambda x: abc(x) )\n",
    "    except: print(\"\\nBalance columns missing\")\n",
    "\n",
    "    try:\n",
    "        wdl=[c for c in df.columns if \"WITHDRAW\" in str(c).upper() ][0]\n",
    "    except:\n",
    "        try:\n",
    "            wdl=[c for c in df.columns if \"DEBIT\" in str(c).upper() ][0]\n",
    "        except: pass \n",
    "\n",
    "    try:\n",
    "        dep=[c for c in df.columns if \"DEPOSIT\" in str(c).upper() ][0]\n",
    "    except:\n",
    "        try:\n",
    "            dep=[c for c in df.columns if \"CREDIT\" in str(c).upper() ][0]\n",
    "        except: pass\n",
    "\n",
    "    df[[wdl, dep]] = df[[wdl, dep]].replace({\"NA\":np.nan, \"-\":np.nan,\"0\":np.nan,\"\":np.nan})\n",
    "\n",
    "    try:\n",
    "        auto=[c for c in df.columns if \"AUTOSWEEP\" in str(c).upper() ][0]\n",
    "        for j,i in enumerate(df[auto]):\n",
    "            if isnan(i) == False:\n",
    "                df[wdl][j] = df[auto][j]\n",
    "            else:\n",
    "                pass\n",
    "    except: pass\n",
    "\n",
    "    try:\n",
    "        rev=[c for c in df.columns if \"REVERSE\" in str(c).upper() ][0]\n",
    "        for j,i in enumerate(df[rev]):\n",
    "            if isnan(i) == False:\n",
    "                df[dep][j] = df[rev][j]\n",
    "            else:\n",
    "                pass\n",
    "    except: pass\n",
    "\n",
    "    df[dep]=df[dep].apply( lambda x: x.split(' ')[0] if type(x) == str else x )\n",
    "    df[wdl]=df[wdl].apply( lambda x: x.split(' ')[0] if type(x) == str else x )\n",
    "    df.to_csv(\"check.csv\", index=0)\n",
    "    df[wdl]=df[wdl].astype(str).apply(lambda x: str(x).replace(\"\\r\",\"\").replace(\",\",\"\").replace(\"Cr\",\"\").replace(\"Dr\",\"\")).astype(float) *-1\n",
    "    df[dep]=df[dep].astype(str).apply(lambda x: str(x).replace(\"\\r\",\"\").replace(\",\",\"\").replace(\"Cr\",\"\").replace(\"Dr\",\"\")).astype(float)\n",
    "    df[bal]=df[bal].astype(str).apply(lambda x:str(x).replace(\"\\r\",\"\").replace(\",\",\"\").replace(\"Cr\",\"\").replace(\"Dr\",\"\")).astype(float)\n",
    "\n",
    "    try:\n",
    "        for i in df.index:\n",
    "            if df[\"bal\"][i] == \"Dr\":\n",
    "                df[bal][i] = df[bal][i]*-1\n",
    "            else:\n",
    "                pass\n",
    "    except:pass\n",
    "\n",
    "    try:\n",
    "        df.drop(['bal'], axis=1, inplace=True)\n",
    "    except:pass\n",
    "\n",
    "    try:\n",
    "        df.drop([auto], axis=1, inplace=True)\n",
    "    except:pass\n",
    "\n",
    "    try:\n",
    "        df.drop([rev], axis=1, inplace=True)\n",
    "    except:pass\n",
    "\n",
    "    df = df[[dat,chq,narr,wdl,dep,bal]]\n",
    "    df.columns = [\"Xns Date\",\"Cheque No\",\"Narration\",\"Debits\",\"Credits\",\"Balance\"]\n",
    "\n",
    "#     df.drop_duplicates(inplace = True)\n",
    "\n",
    "    # return df\n",
    "\n",
    "    df.to_excel(\"axis13.xlsx\", index=False)\n",
    "\n",
    "try:\n",
    "    f = r'C:\\Users\\MudraCircle\\Desktop\\bks_raw\\Parsing_testing\\Axis_new\\files\\axis13.pdf'\n",
    "    try:\n",
    "        df = came(f); df = proceed(df); df = axis_filter(df)\n",
    "        print(\"Completed.\")\n",
    "    except:\n",
    "        print(\"Not parsed\")\n",
    "        pass\n",
    "except:\n",
    "    print(\"\\n Can't parse\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
